

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Step 1: Load dataset
data = pd.read_csv("car-price-predictionused-cars.csv")  # Ensure this matches your dataset filename

# Step 2: Handle missing values
data.dropna(inplace=True)

# Step 3: Convert categorical features
categorical_features = ["Fuel_Type", "Selling_type", "Transmission"]
encoder = OneHotEncoder(handle_unknown="ignore", drop="first")
encoded_data = encoder.fit_transform(data[categorical_features]).toarray()

# Step 4: Scale numerical features
numerical_features = ["Present_Price", "Driven_kms", "Year", "Owner"]
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data[numerical_features])

# Step 5: Prepare final dataset
X = np.hstack((encoded_data, scaled_data))  # Combine processed features
y = data["Selling_Price"].values  # Target variable

# Step 6: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 7: Train model (Random Forest)
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"RÂ² Score: {r2:.2f}")

# Step 9: Visualization
plt.scatter(y_test, y_pred, alpha=0.5)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual vs Predicted Car Prices")
plt.show()